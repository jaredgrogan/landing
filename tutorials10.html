<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Comprehensive TensorFlow Image Classification Tutorial</title>
    <style>
        :root {
            --primary-color: #FF6F00;
            --secondary-color: #455A64;
            --bg-color: #121212;
            --text-color: #E0E0E0;
            --header-footer-color: #111111;
        }
        body {
            font-family: 'Arial', sans-serif;
            line-height: 1.6;
            color: var(--text-color);
            background-color: var(--bg-color);
            margin: 0;
            padding: 0;
            transition: background-color 0.3s, color 0.3s;
        }
        body.light-mode {
            --bg-color: #FFFFFF;
            --text-color: #333333;
            --header-footer-color: #F5F5F5;
        }
        .container {
            width: 80%;
            margin: auto;
            overflow: hidden;
            padding: 20px;
        }
        header {
            background: var(--header-footer-color);
            color: var(--text-color);
            padding-top: 30px;
            min-height: 70px;
            border-bottom: var(--secondary-color) 3px solid;
        }
        header h1 {
            margin: 0;
            text-align: center;
            padding-bottom: 20px;
        }
        nav {
            background: var(--header-footer-color);
            color: var(--text-color);
            padding: 10px 0;
        }
        nav ul {
            padding: 0;
            list-style: none;
            text-align: center;
        }
        nav li {
            display: inline;
            margin: 0 10px;
        }
        nav a {
            color: var(--text-color);
            text-decoration: none;
        }
        .section {
            background: var(--header-footer-color);
            margin: 20px 0;
            padding: 20px;
            border-radius: 5px;
            box-shadow: 0 0 10px rgba(0,0,0,0.1);
        }
        code {
            background: #2D2D2D;
            border: 1px solid #444;
            border-left: 3px solid var(--primary-color);
            color: #CCCCCC;
            page-break-inside: avoid;
            font-family: monospace;
            font-size: 15px;
            line-height: 1.6;
            margin-bottom: 1.6em;
            max-width: 100%;
            overflow: auto;
            padding: 1em 1.5em;
            display: block;
            word-wrap: break-word;
        }
        .btn {
            display: inline-block;
            background: var(--primary-color);
            color: white;
            padding: 10px 20px;
            border: none;
            cursor: pointer;
            text-decoration: none;
            border-radius: 5px;
        }
        .btn:hover {
            background: var(--secondary-color);
        }
        .quiz {
            background-color: var(--header-footer-color);
            border: 2px solid var(--primary-color);
            padding: 20px;
            margin-top: 20px;
            border-radius: 5px;
        }
        .quiz h3 {
            margin-top: 0;
        }
        .quiz button {
            margin-top: 10px;
        }
        #search-container {
            margin: 20px 0;
        }
        #search-input {
            width: 70%;
            padding: 10px;
            font-size: 16px;
        }
        #search-button {
            padding: 10px 20px;
            font-size: 16px;
            background: var(--primary-color);
            color: white;
            border: none;
            cursor: pointer;
        }
        .diagram {
            max-width: 100%;
            height: auto;
            display: block;
            margin: 20px auto;
        }
        .key-concept {
            background-color: #2C3E50;
            border-left: 5px solid var(--primary-color);
            padding: 10px;
            margin: 10px 0;
        }
        .troubleshooting {
            background-color: #34495E;
            border: 2px solid #E74C3C;
            padding: 15px;
            margin: 20px 0;
            border-radius: 5px;
        }
        .citation {
            font-size: 0.9em;
            color: #95A5A6;
            margin-top: 5px;
        }
        .collapsible {
            background-color: #2C3E50;
            color: white;
            cursor: pointer;
            padding: 18px;
            width: 100%;
            border: none;
            text-align: left;
            outline: none;
            font-size: 15px;
        }
        .active, .collapsible:hover {
            background-color: #34495E;
        }
        .content {
            padding: 0 18px;
            display: none;
            overflow: hidden;
            background-color: #1A242F;
        }
        .tooltip {
            position: relative;
            display: inline-block;
            border-bottom: 1px dotted #ccc;
        }
        .tooltip .tooltiptext {
            visibility: hidden;
            width: 200px;
            background-color: #555;
            color: #fff;
            text-align: center;
            border-radius: 6px;
            padding: 5px;
            position: absolute;
            z-index: 1;
            bottom: 125%;
            left: 50%;
            margin-left: -100px;
            opacity: 0;
            transition: opacity 0.3s;
        }
        .tooltip:hover .tooltiptext {
            visibility: visible;
            opacity: 1;
        }
    </style>
</head>
<body>
    <header>
        <div class="container">
            <h1>Comprehensive TensorFlow Image Classification Tutorial</h1>
        </div>
    </header>
    <nav>
        <ul>
            <li><a href="#introduction">Introduction</a></li>
            <li><a href="#key-concepts">Key Concepts</a></li>
            <li><a href="#data-preprocessing">Data Preprocessing</a></li>
            <li><a href="#model-building">Model Building</a></li>
            <li><a href="#model-evaluation">Model Evaluation</a></li>
            <li><a href="#troubleshooting">Troubleshooting</a></li>
            <li><a href="#glossary">Glossary</a></li>
        </ul>
    </nav>
    <div class="container">
        <button id="mode-toggle" class="btn">Toggle Dark/Light Mode</button>
        <div id="search-container">
            <input type="text" id="search-input" placeholder="Search topics...">
            <button id="search-button">Search</button>
        </div>

        <section id="introduction" class="section">
            <h2>1. Introduction</h2>
            <p>Welcome to this comprehensive tutorial on image classification using TensorFlow. In this guide, we'll walk through the process of building, training, and evaluating a convolutional neural network (CNN) for image classification tasks.</p>
        </section>

        <section id="key-concepts" class="section">
            <h2>2. Key Concepts</h2>
            <div class="key-concept">
                <h3>Convolutional Neural Network (CNN)</h3>
                <p>A type of deep learning model specifically designed for processing grid-like data, such as images. CNNs use convolutional layers to automatically and adaptively learn spatial hierarchies of features.</p>
                <p class="citation">[1] Goodfellow, I., Bengio, Y., & Courville, A. (2016). Deep Learning. MIT Press.</p>
            </div>
            <div class="key-concept">
                <h3>Activation Function</h3>
                <p>A mathematical function applied to the output of a neuron to introduce non-linearity into the model. Common activation functions include ReLU, sigmoid, and tanh.</p>
                <p class="citation">[2] Nwankpa, C. et al. (2018). Activation Functions: Comparison of trends in Practice and Research for Deep Learning.</p>
            </div>
            <div class="key-concept">
                <h3>Backpropagation</h3>
                <p>An algorithm used to train neural networks by calculating the gradient of the loss function with respect to the weights of the network. It efficiently computes these gradients using the chain rule of calculus.</p>
                <p class="citation">[3] Rumelhart, D. E., Hinton, G. E., & Williams, R. J. (1986). Learning representations by back-propagating errors. Nature, 323(6088), 533-536.</p>
            </div>
            <div class="key-concept">
                <h3>Overfitting</h3>
                <p>A modeling error that occurs when a function is too closely fit to a limited set of data points, potentially capturing noise rather than underlying patterns. This results in poor generalization to new, unseen data.</p>
                <p class="citation">[4] Hawkins, D. M. (2004). The problem of overfitting. Journal of chemical information and computer sciences, 44(1), 1-12.</p>
            </div>
            <div class="key-concept">
                <h3>Data Augmentation</h3>
                <p>A technique used to increase the diversity of training data by applying various transformations (e.g., rotation, flipping, scaling) to existing samples. This helps improve model generalization and reduce overfitting.</p>
                <p class="citation">[5] Shorten, C., & Khoshgoftaar, T. M. (2019). A survey on Image Data Augmentation for Deep Learning. Journal of Big Data, 6(1), 60.</p>
            </div>
        </section>

        <section id="data-preprocessing" class="section">
            <h2>3. Data Preprocessing</h2>
            <p>Before we can train our model, we need to preprocess our image data. This typically involves:</p>
            <ul>
                <li>Loading and organizing the dataset</li>
                <li>Resizing images to a consistent size</li>
                <li>Normalizing pixel values</li>
                <li>Splitting data into training, validation, and test sets</li>
                <li>Data augmentation (optional but recommended)</li>
            </ul>
            <button class="collapsible">View Code</button>
            <div class="content">
                <code>
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Create an ImageDataGenerator for data augmentation and preprocessing
datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    horizontal_flip=True,
    validation_split=0.2)  # 20% of data will be used for validation

# Load training data
train_generator = datagen.flow_from_directory(
    'path/to/train/directory',
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical',
    subset='training')

# Load validation data
validation_generator = datagen.flow_from_directory(
    'path/to/train/directory',
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical',
    subset='validation')
                </code>
            </div>
        </section>

        <section id="model-building" class="section">
            <h2>4. Model Building</h2>
            <p>In this section, we'll build a Convolutional Neural Network (CNN) for image classification using TensorFlow and Keras.</p>
            <img src="https://miro.medium.com/max/2000/1*vkQ0hXDaQv57sALXAJquxA.jpeg" alt="CNN Architecture" class="diagram">
            <button class="collapsible">View Code</button>
            <div class="content">
                <code>
import tensorflow as tf

model = tf.keras.Sequential([
    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),
    tf.keras.layers.MaxPooling2D((2, 2)),
    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),
    tf.keras.layers.MaxPooling2D((2, 2)),
    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(10, activation='softmax')
])

model.compile(optimizer='adam',
              loss='categorical_crossentropy',
              metrics=['accuracy'])
                </code>
            </div>
            <button class="collapsible">Code Explanation</button>
            <div class="content">
                <p>This code defines a CNN model using TensorFlow's Keras API. Here's a breakdown of each layer:</p>
                <ul>
                    <li>Conv2D layers: Apply convolution operations to extract features from the input image.</li>
                    <li>MaxPooling2D layers: Reduce the spatial dimensions of the feature maps.</li>
                    <li>Flatten layer: Converts the 2D feature maps to a 1D vector.</li>
                    <li>Dense layers: Fully connected layers for classification.</li>
                </ul>
                <p>The model is compiled with the Adam optimizer, categorical crossentropy loss (suitable for multi-class classification), and accuracy as the evaluation metric.</p>
            </div>
        </section>

        <section id="model-evaluation" class="section">
            <h2>5. Model Evaluation</h2>
            <p>After training our model, it's crucial to evaluate its performance accurately.</p>
            <button class="collapsible">View Code</button>
            <div class="content">
                <code>
# Train the model
history = model.fit(
    train_generator,
    steps_per_epoch=train_generator.samples // train_generator.batch_size,
    epochs=50,
    validation_data=validation_generator,
    validation_steps=validation_generator.samples // validation_generator.batch_size)

# Evaluate the model
test_loss, test_acc = model.evaluate(test_generator, verbose=2)
print(f'Test accuracy: {test_acc}')

# Make predictions
predictions = model.predict(test_generator)
                </code>
            </div>
        </section>

        <section id="troubleshooting" class="section">
            <h2>6. Troubleshooting and FAQ</h2>
            <div class="troubleshooting">
                <h3>Common Pitfall: Using the wrong loss function</h3>
                <p>For multi-

</code>
            </div>
            <button class="collapsible">Visualization and Analysis</button>
            <div class="content">
                <code>
import matplotlib.pyplot as plt
import numpy as np
from sklearn.metrics import confusion_matrix, classification_report

# Plot training history
plt.figure(figsize=(12, 4))
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.legend()
plt.title('Model Accuracy')
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.legend()
plt.title('Model Loss')
plt.show()

# Confusion Matrix
cm = confusion_matrix(test_generator.classes, np.argmax(predictions, axis=1))
plt.figure(figsize=(10, 8))
plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)
plt.title('Confusion Matrix')
plt.colorbar()
tick_marks = np.arange(len(test_generator.class_indices))
plt.xticks(tick_marks, test_generator.class_indices, rotation=45)
plt.yticks(tick_marks, test_generator.class_indices)
plt.tight_layout()
plt.ylabel('True label')
plt.xlabel('Predicted label')
plt.show()

# Classification Report
print(classification_report(test_generator.classes, np.argmax(predictions, axis=1), target_names=test_generator.class_indices.keys()))
                </code>
            </div>
        </section>

        <section id="troubleshooting" class="section">
            <h2>6. Troubleshooting and FAQ</h2>
            <div class="troubleshooting">
                <h3>Common Pitfall: Using the wrong loss function</h3>
                <p>For multi-class classification, use 'categorical_crossentropy'. For binary classification, use 'binary_crossentropy'.</p>
            </div>
            <div class="troubleshooting">
                <h3>Error: "ValueError: Shapes (None, 1) and (None, 10) are incompatible"</h3>
                <p>Ensure your labels are one-hot encoded for categorical_crossentropy. You can use: tf.keras.utils.to_categorical(y, num_classes)</p>
            </div>
            <div class="troubleshooting">
                <h3>Model not improving during training</h3>
                <p>Check your learning rate. If it's too high, the model might not converge. If it's too low, training might be slow. Try using a learning rate scheduler or the Adam optimizer, which adapts the learning rate.</p>
            </div>
            <div class="troubleshooting">
                <h3>Out of Memory (OOM) error</h3>
                <p>Reduce batch size, simplify your model architecture, or use data generators to load data in batches instead of loading all data into memory.</p>
            </div>
            <div class="troubleshooting">
                <h3>Overfitting</h3>
                <p>Implement regularization techniques such as dropout, L1/L2 regularization, or data augmentation. Also, consider reducing model complexity or using early stopping.</p>
            </div>
            <div class="troubleshooting">
                <h3>Poor generalization to new data</h3>
                <p>Ensure your training data is representative of the problem space. Use techniques like cross-validation to get a better estimate of model performance. Consider using transfer learning with a pre-trained model.</p>
            </div>
        </section>

        <section id="glossary" class="section">
            <h2>7. Glossary</h2>
            <dl>
                <dt>Epoch</dt>
                <dd>One complete pass through the entire training dataset.</dd>
                
                <dt>Batch Size</dt>
                <dd>The number of training examples utilized in one iteration.</dd>
                
                <dt>Gradient Descent</dt>
                <dd>An optimization algorithm used to minimize the loss function by iteratively moving in the direction of steepest descent.</dd>
                
                <dt>Regularization</dt>
                <dd>Techniques used to prevent overfitting by adding a penalty term to the loss function.</dd>
                
                <dt>Dropout</dt>
                <dd>A regularization technique where randomly selected neurons are ignored during training to prevent over-reliance on any one feature.</dd>
                
                <dt>Transfer Learning</dt>
                <dd>A technique where a model developed for a task is reused as the starting point for a model on a second task.</dd>
                
                <dt>Feature Map</dt>
                <dd>The output of applying a filter to an input image in a convolutional layer.</dd>
                
                <dt>Softmax</dt>
                <dd>An activation function that turns numbers into probabilities that sum to one, often used in the output layer of a multi-class classification model.</dd>
                
                <dt>Cross-Validation</dt>
                <dd>A resampling procedure used to evaluate machine learning models on a limited data sample.</dd>
            </dl>
        </section>

        <section id="further-reading" class="section">
            <h2>8. Further Reading</h2>
            <ul>
                <li><a href="https://www.tensorflow.org/tutorials">TensorFlow Tutorials</a></li>
                <li><a href="https://www.coursera.org/specializations/deep-learning">Deep Learning Specialization on Coursera</a></li>
                <li><a href="https://arxiv.org/abs/1512.03385">Deep Residual Learning for Image Recognition</a></li>
                <li><a href="https://arxiv.org/abs/1409.1556">Very Deep Convolutional Networks for Large-Scale Image Recognition</a></li>
            </ul>
        </section>

        <a href="#" class="btn">Back to Top</a>
    </div>

    <script>
        // Dark/Light mode toggle
        const modeToggle = document.getElementById('mode-toggle');
        modeToggle.addEventListener('click', () => {
            document.body.classList.toggle('light-mode');
        });

        // Search functionality
        const searchInput = document.getElementById('search-input');
        const searchButton = document.getElementById('search-button');
        const sections = document.querySelectorAll('.section');

        searchButton.addEventListener('click', () => {
            const searchTerm = searchInput.value.toLowerCase();
            sections.forEach(section => {
                if (section.textContent.toLowerCase().includes(searchTerm)) {
                    section.style.display = 'block';
                } else {
                    section.style.display = 'none';
                }
            });
        });

        // Collapsible sections
        var coll = document.getElementsByClassName("collapsible");
        var i;

        for (i = 0; i < coll.length; i++) {
            coll[i].addEventListener("click", function() {
                this.classList.toggle("active");
                var content = this.nextElementSibling;
                if (content.style.display === "block") {
                    content.style.display = "none";
                } else {
                    content.style.display = "block";
                }
            });
        }
        
        // Tooltip functionality
        var tooltips = document.getElementsByClassName("tooltip");
        for (var i = 0; i < tooltips.length; i++) {
            tooltips[i].addEventListener("mouseover", function() {
                var tooltipText = this.getElementsByClassName("tooltiptext")[0];
                tooltipText.style.visibility = "visible";
                tooltipText.style.opacity = "1";
            });
            tooltips[i].addEventListener("mouseout", function() {
                var tooltipText = this.getElementsByClassName("tooltiptext")[0];
                tooltipText.style.visibility = "hidden";
                tooltipText.style.opacity = "0";
            });
        }
    </script>
</body>
</html>
